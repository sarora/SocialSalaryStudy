---
title: "Exploratory Data Analysis"
author: "S. Arora, J. Harmse, V. Mulholland"
date: "April 9, 2018"
header-includes:
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \fancyhead[LE,RO]{Social Salary Study}
- \fancyfoot[CO,CE]{DSCI554-Experimentation and Causal Inference}
- \fancyfoot[LE,RO]{\thepage}
output: pdf_document
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, warning=F, message=F}
library(tidyverse)
```

# Data Pre-processing

## Anonymity

In order to maintain user privacy a few manipulations were handled before the raw data was uploaded to the analysis repository. Any confidential information such as IP addresses were ommited, as well as any respondents that did not accept the confidentiallity agreement. 

### Pre-processing Workflow

These were the first steps applied to `surveydata_clean.rds` when the data was downloaded raw from _Survey Monkey_. 

```
# removing confidential data
survey_results <- read_csv(file = '../../survey_data/Demographic Survey.csv', skip = 1)
survey_results <- survey_results[, 10:ncol(survey_results)]

#import data
# survey_results <- read_csv(file = '../../survey_data/Demographic Survey.csv') # local path - remove identifiers beforehand

# redefine column names
colnames(survey_results) <- c('consent', 'country', 'salary_base', 'salary_expect', 'no_increase_acceptance', 
                           'living_expenses', 'savings', 'vacation', 'daily_leisure', 'consumption_goods', 
                           'sports_hobbies', 'other')

# spending categories
spending_cats <- c('living_expenses', 'savings', 'vacation', 'daily_leisure', 'consumption_goods', 
                           'sports_hobbies', 'other')

# remove no consent
survey_results <- survey_results %>% filter(consent %in% c('Yes'))

# add observation id
survey_results$id <- 1:nrow(survey_results)

# save raw clean data
saveRDS(survey_results, file = '../data/processed/surveydata_clean.rds')

# remove all traces
rm(survey_results)
```
Once the data is pre-processed, it is reimported and the columns and categories are defined. 

```{r}
# import clean data
survey_results <-  readRDS(file = '../data/processed/surveydata_clean.rds')  # local path - remove identifiers beforehand
survey_results %>% head()

# redefine column names
colnames(survey_results) <- c('consent', 'country', 'salary_base', 'salary_expect', 'no_increase_acceptance', 
                           'living_expenses', 'savings', 'vacation', 'daily_leisure', 'consumption_goods', 
                           'sports_hobbies', 'other')

# spending categories
spending_cats <- c('living_expenses', 'savings', 'vacation', 'daily_leisure', 'consumption_goods', 
                           'sports_hobbies', 'other')


```


A new variable was created as a measurement of relative expected increase in salary. This variable corresponds to the response variable of our linear regression model. The benefits of using a ratio meant that there would be less extra manipulations and potential confounding variables behind adjustments for foreign currencies. This ratio of the expected salary over the base salary of a respondent is indicative of a person's desire for financial gains. This type of metric introduces a set of confounding aspects when we do not account for specific demographic groups that would naturally behave a certain way with regards to financial inclinations. For instance, people of a certain age will typically not expect major salary increases when nearing retirement while students working while pursing a higher education degree may be recipients of a very small income in comparison to a year from now when they will enter the job market. Had the survey been organized to reach a larger demographic, more questions could have been added to delineate the confounding variables into groups including demographics such as age, occupation, etc. Another solution to handle this would have been to adjust the wording of the questions in a way that was more explicit, say instead of "" we could have specified that if they are part-time employed or a student, to imagine they are on the full-time job market when considering their qualifications and salary estimates. **IS THIS WHERE PAUL TALKS ABOUT BLOCKS** 

```{r}
# ensure any NA values are set to 0
survey_results[ , spending_cats][is.na(survey_results[,spending_cats])] <- 0

# converting char to numeric
survey_results$salary_base <- as.numeric(as.character(survey_results$salary_base))
survey_results$salary_expect <- as.numeric(as.character(survey_results$salary_expect))
ratios = survey_results$salary_expect/survey_results$salary_base

# add ratio 
survey_results <- survey_results %>% mutate(ratio = ratios)
```

Having chosen to remove outliers on the basis that with a small number of observations applying the statistical method of removing outliers greater than two standard deviations could be erroneous since it cannot be deduced with certainty which distribution is being represented. That being said, a combination of visual assessments and quantile analysis allowed a reasonable upper and lower limit to be chosen.

EXPLAIN REASONING HERE

-----------basic plot showing outliers
```{r}
# --------------------------------------remove 2 standard deviations
# remove outliers
survey_results <- survey_results %>% 
  dplyr::filter(ratio < 10 & 
           ratio > 0.1)
```


Each variable is summarized. Since it is difficult to highlight important information from a summary table containing so many variables, a _______plot was generated. 

```{r}
# data summary table
sum.tb <- summary(survey_results)
sum.tb
# labels(survey_results) <- 
# library(knitr)
# library(papeR)
# xtable(summarize(survey_results, type = "numeric"))
# xtable(summarize(Orthodont, type = "factor", variables = "Sex"))
# xtable(summarize(Orthodont, type = "numeric", group = "Sex"))
# 
# library("knitr")
# summarize(survey_results, type = "factor")
# kable(summarize(Orthodont, type = "numeric"))
# kable(summarize(Orthodont, type = "factor", variables = "Sex", cumulative = TRUE))
# kable(summarize(Orthodont, type = "numeric", group = "Sex", test = FALSE))
```


```{r}
# get ratio
survey_results <- survey_results %>% 
  mutate(ratio = salary_expect/salary_base)
```

------------plot ratio

The questions were designed to make use of a monetary ratio to avoid additional manipulation of currency data.

vvvvvvvvvvvvvvvvv ------not required
```{r}
# generic first model
lm_survey <- lm(ratio ~ no_increase_acceptance + 
                  living_expenses + 
                  savings + 
                  vacation + 
                  daily_leisure + 
                  consumption_goods + 
                  sports_hobbies + 
                  other, data = survey_results)

summary(lm_survey)
```
# Outliers

Considerations were made to account for outliers. Justification for removing outliers beyond two standard deviations from the mean 
- typos
-




---------------- boxplot function to remove outliers
---------------- boxplot plot

```{r}
# ---------------------------------fix for 2SD
# remove outliers
survey_results <- survey_results %>% 
  filter(ratio < 10 & 
           ratio > 0.1)

# replace NA spendings with 0

survey_results[ , spending_cats][is.na(survey_results[ , spending_cats])] <- 0
```
# Model

A first take at modelling the data .........


```{r}
# generic first model (outliers removed and data cleaned)
lm_survey <- lm(ratio ~ no_increase_acceptance + 
                  living_expenses + 
                  savings + 
                  vacation + 
                  daily_leisure + 
                  consumption_goods + 
                  sports_hobbies + 
                  other, data = survey_results)

summary(lm_survey)
```

```{r}
# gathered data
survey_tidy <- NULL

non_spendings <- colnames(survey_results)[!(colnames(survey_results) %in% spending_cats)]

for (spending in spending_cats){
  temp <- survey_results[ , non_spendings]
  temp$spending_cat <- spending
  temp$spending_val <- survey_results[[spending]]
  survey_tidy <- rbind(survey_tidy, temp)
}
```

Standardizing the spendings according to their living expenses. 

```{r}
# spending as a ratio of living expenses
for (i in unique(survey_tidy$id)){
  temp <- survey_tidy %>% filter(id == i)
  user_living <- as.numeric(temp %>% filter(temp$spending_cat == 'living_expenses') %>% select(spending_val))
  survey_tidy[survey_tidy$id == i, 'spending_ratio'] <- temp$spending_val/user_living
}
```



```{r}
# store variable p-values
p_vals <- data.frame('category' = character(length(spending_cats)), 'slope' = numeric(length(spending_cats)), 'p_value' = numeric(length(spending_cats)), stringsAsFactors = FALSE)

# run linear models for each spending category individually
count <-  0

for (i in spending_cats){
  count <- count + 1
  temp <- survey_tidy %>% filter(spending_cat == i)
  temp <- temp %>% filter(!is.na(spending_ratio) & abs(spending_ratio) != Inf)
  temp_lm <- lm(ratio ~ spending_ratio, data = temp)
  lm_summary <- summary(temp_lm)
  p_vals[count, 'category'] <- as.character(i)
  p_vals[count, 'slope'] <- temp_lm$coefficients[2]
  p_vals[count, 'p_value'] <- ifelse(nrow(lm_summary$coefficients) > 1, lm_summary$coefficients[2 , 4], NA)
}
```

```{r}
p_vals
```


